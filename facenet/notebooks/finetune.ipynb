{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1598712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2874ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../datasets/train\"\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a86e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770a94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2014aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + \"_cropped\"))\n",
    "    for p, _ in dataset.samples\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb0993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 of 6"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print(\"\\rBatch {} of {}\".format(i+1, len(loader)), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfa2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(mtcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88da84fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e9e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(dataset.class_to_idx)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e149df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer=optimizer, milestones=[5, 10])\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732d1dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152,), (38,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_dir + '_cropped', transform=trans)\n",
    "img_inds = np.arange(len(dataset))\n",
    "np.random.shuffle(img_inds)\n",
    "train_inds = img_inds[:int(0.8*len(img_inds))]\n",
    "val_inds = img_inds[int(0.8*len(img_inds)):]\n",
    "\n",
    "train_inds.shape, val_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea490ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_inds)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_inds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09101c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a3c8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "Valid |     2/2    | loss:    0.7244 | fps:   88.7120 | acc:    0.4896   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7244), {'fps': tensor(88.7120), 'acc': tensor(0.4896)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' *10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True,\n",
    "    device=device, writer=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6c030e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.1902 | fps:  157.6107 | acc:    0.8792   \n",
      "Valid |     2/2    | loss:   20.9496 | fps:   91.9187 | acc:    0.3385   \n",
      "\n",
      "Epoch 2/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0107 | fps:  119.7791 | acc:    1.0000   \n",
      "Valid |     2/2    | loss:  127.7221 | fps:   94.8000 | acc:    0.3385   \n",
      "\n",
      "Epoch 3/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0100 | fps:  124.9404 | acc:    0.9937   \n",
      "Valid |     2/2    | loss:    0.0000 | fps:   92.5174 | acc:    1.0000   \n",
      "\n",
      "Epoch 4/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0008 | fps:  123.5540 | acc:    1.0000   \n",
      "Valid |     2/2    | loss:    0.0000 | fps:   92.1170 | acc:    1.0000   \n",
      "\n",
      "Epoch 5/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0000 | fps:  122.8081 | acc:    1.0000   \n",
      "Valid |     2/2    | loss:    0.0000 | fps:   89.4230 | acc:    1.0000   \n",
      "\n",
      "Epoch 6/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0004 | fps:  119.9467 | acc:    1.0000   \n",
      "Valid |     2/2    | loss:    0.0000 | fps:   91.0662 | acc:    1.0000   \n",
      "\n",
      "Epoch 7/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0000 | fps:  123.0830 | acc:    1.0000   \n",
      "Valid |     2/2    | loss:    0.0000 | fps:   90.4517 | acc:    1.0000   \n",
      "\n",
      "Epoch 8/8\n",
      "----------\n",
      "Train |     5/5    | loss:    0.0001 | fps:  123.1894 | acc:    1.0000   \n",
      "Valid |     2/2    | loss:    0.0000 | fps:   85.7065 | acc:    1.0000   \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{epochs}')\n",
    "    print('-'*10)\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True,\n",
    "        device=device, writer=writer\n",
    "    )\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7503d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model successfully saved to ../../models/facenet_v1.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = '../../models/facenet_v1.pth'\n",
    "\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(resnet.state_dict(), save_path)\n",
    "\n",
    "print(f\"\\nModel successfully saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874aab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
